<!DOCTYPE html>
<html lang='en'>

<head>
    <base href="..">
    <link rel="shortcut icon" type="image/png" href="assets/logo.png"/>
    <link rel="stylesheet" type="text/css" media="all" href="assets/main.css"/>
    <script type="text/javascript" async
        src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=default">
    </script>
    <meta name="description" content="Conference Template">
    <meta name="resource-type" content="document">
    <meta name="distribution" content="global">
    <meta name="KeyWords" content="Conference">
    <title>Program | SAM 2024</title>
</head>

<body>

    <div class="banner">
        <style>
            img { 
              width: 1000px;
              margin-top: 160px; 
            }
          </style>
        <img src="assets/salzburg.jpg" alt="Conference Template Banner">
        <div class="top-left">
            <!--<span class="title1">Conference</span><span class="title2">Template</span> <span class="year">2525</span>-->
            <span style="color:rgb(0, 85, 255); font-size: 50px">Fifth International Workshop on</span> <br> <br> <span style="color:rgb(0, 85, 255); font-size: 45px"> Statistical Analyses of Multi-Outcome Data</span>
        </div>
        <div class="bottom-right">
            July 9-10, 2024 <br> Salzburg, Austria
        </div>
    </div>

    <table class="navigation">
        <tr>
            <td class="navigation">
                <a title="Conference Home Page" href=".">Home</a>
            </td>
            <td class="navigation">
                <a title="Register for the Conference" href="registration">Registration</a>
            </td>
            <td class="navigation">
                <a title="Conference Submission" href="submission">Submission</a>
            </td>
            <td class="navigation">
                <a class="current" title="Conference Program" href="program">Program</a> 
            </td>
            <td class="navigation">
                <a title="Conference Accommodation" href="accommodation">Accommodation</a>
            </td>
            <td class="navigation">
                <a title="Conference Venue" href="venue">Venue</a>
            </td>
            <td class="navigation">
                <a title="Conference Organizers" href="organizer">Organizers</a>
            </td>
            <td class="navigation">
                <a title="Conference Sponsors" href="sponsor">Sponsors</a>
            </td>
            <td class="navigation">
                <a title="Conference History" href="history">History</a>
            </td>
        </tr>
    </table>

    <h2>Conference Program</h2>

    <table class="styled-table" style="width:70%">
        <thead>
            <tr>
            <th>Time</th>
            <th>7/9/2024</th>
            <th>Time</th>
            <th>7/10/2024</th>
            </tr>
        </thead>
        <tbody>
            <tr>
            <td>8:50-9:00</td>
            <td>Opening Remarks</td>
            <td>9:00-10:45</td>
            <td>Parallel Invited Sessions  </td>
            </tr>
            <tr>
            <td>9:00-10:00</td>
            <td>Keynote 1 by Ian McKeague</td>
            <td>10:45-11:00</td>
            <td>Break </td>
            </tr>
            <tr>
            <td>10:00-10:15</td>
            <td>Break</td>
            <td>11:00-12:45</td>
            <td>Parallel Invited Sessions </td>
            </tr>
            <tr>
                <td>10:15-12:00</td>
                <td>Parallel Invited Sessions </td>
                <td>12:45-1:45</td>
                <td>Lunch</td>
            </tr>
            <tr>
                <td>12:00-1:00</td>
                <td>Lunch</td>
                <td>1:45-3:30 </td>
                <td>Parallel Invited Sessions </td>
            </tr>
            <tr>
                <td>1:00-2:45 </td>
                <td>Parallel Invited Sessions </td>
                <td>3:30-3:45</td>
                <td>Break</td>
            </tr>
            <tr>
                <td>2:45-3:00</td>
                <td>Break</td>
                <td>3:45-4:45 </td>
                <td>Parallel Contributed Sessions</td>
            </tr>
            <tr>
                <td>3:00-4:45 </td>
                <td>Parallel Invited Sessions </td>
                <td>4:45-5:00 </td>
                <td>Break</td>
            </tr>
            <tr>
                <td>4:45-5:00</td>
                <td>Break</td>
                <td>5:00-6:00</td>
                <td>Keynote 2 by Markus Pauly </td>
            </tr>
            <tr>
                <td>5:00-6:00</td>
                <td>Parallel Contributed Sessions </td>
                <td>6:00-6:10</td>
                <td>Closing Remarks</td>
            </tr>
            <tr>
                <td>6:00-8:30</td>
                <td>Banquet/Junior Research Award</td>
                <td></td>
                <td></td>
            </tr>
        </tbody>
    </table>


    <h2>Invited Sessions</h2>

    <button type="button" class="collapsible">Tentative: Extreme value analysis</button>
    <div class="content">
        <table id="PUTSPEAKERNAMEHERE">
            <tr>
                <td class="organizer">
                    Judy Wang (Organizer)
                </td>
            </tr>
            <tr>
                <td class="speaker">
                    Daniela Castro-Camilo
                </td>
            </tr>
            <tr>
                <td class="speaker">
                    Sebastian Engelke
                </td>
            </tr>
            <tr>
                <td class="speaker">
                    Tiandong Wang
                </td>
            </tr>
            <tr>
                <td class="speaker">
                    Chen Zhou
                </td>
            </tr>

            <tr>
                <td class="title">
                    A Bayesian multivariate extreme value mixture model
                </td>
            </tr>
            <tr>
                <td class="abstract">
                    Daniela Castro-Camilo<br>
                    Lecturer in Statistics, School of Mathematics and Statistics, University of Glasgow, Glasgow G12 8QQ
                    <br>
                    Daniela.CastroCamilo@glasgow.ac.uk
                </td>
            </tr>
            <tr>
                <td class="abstract">
                    Impact assessment of natural hazards requires the consideration of both extreme and non-extreme events. Extensive research has been conducted on the joint modelling of bulk and tail in univariate settings; however, the corresponding body of research in the context of multivariate analysis is comparatively scant. This study extends the univariate joint modelling of bulk and tail to the multivariate framework. Specifically, it pertains to cases where multivariate observations exhibit extremity in at least one component.
                    <br>
                    We propose a multivariate extreme value mixture model that assumes a parametric model to capture the bulk of the distribution, which is in the max-domain of attraction of a multivariate extreme value distribution. The multivariate tail is described by the asymptotically justified multivariate generalized Pareto distribution. Bayesian inference based on multivariate random-walk Metropolis-Hastings and the automated factor slice sampler allows us to easily incorporate uncertainty from the threshold selection. The performance of our model is tested using different simulation scenarios, and the applicability of our model is illustrated using temperature records in the UK that show the need to accurately describe the joint tail behaviour.
                </td>
            </tr>

            <tr>
                <td class="title">
                    Machine learning beyond the data range: an extreme value perspective
                </td>
            </tr>
            <tr>
                <td class="abstract">
                    Sebastian Engelke<br>
                    Associate Professor, Research Center for Statistics, University of Geneva
                    <br>
                    Daniela.CastroCamilo@glasgow.ac.uk
                </td>
            </tr>
            <tr>
                <td class="abstract">
                    Machine learning methods perform well in prediction tasks within the range of the training data. These methods typically break down when interest is in (1) prediction in areas of the predictor space with few or no training observations; or (2) prediction of quantiles of the response that go beyond the observed records. Extreme value theory provides the mathematical foundation for extrapolation beyond the range of the training data, both in the dimension of the predictor space and the response variable. In this talk we present recent methodology that combines this extrapolation theory with flexible machine learning methods to tackle the out-of-distribution generalization problem (1) and the extreme quantile regression problem (2). We show the practical importance of prediction beyond the training observations in environmental and climate applications, where domain shifts in the predictor space occur naturally due to climate change and risk assessment for extreme quantiles is required.
                </td>
            </tr>

            <tr>
                <td class="title">
                    Testing for Strong VS Full Dependence
                </td>
            </tr>
            <tr>
                <td class="abstract">
                    Tiandong Wang, Ph.D.<br>
                    Shanghai Center for Mathematical Sciences, Fudan University<br>
                    td_wang@fudan.edu.cn 
                </td>
            </tr>
            <tr>
                <td class="abstract">
                    Preferential attachment models of network growth are bivariate heavy tailed models for in- and out-degree with limit measures which either concentrate on a ray of positive slope from the origin or on all of the positive quadrant depending on whether the model includes reciprocity or not. Concentration on the ray is called full dependence. If there were a reliable way to distinguish full dependence from not-full, we would have guidance about which model to choose. This motivates investigating tests that distinguish between (i) full dependence; (ii) strong dependence (limit measure concentrates on a proper subcone of the positive quadrant; (iii) concentration on positive quadrant. We give two test statistics and discuss their asymptotically normal behavior under full and not-full dependence.
                    <br>
                    This is a joint work with Prof. Sidney Resnick at Cornell University. 
                </td>
            </tr>

            <tr>
                <td class="title">
                    Tail copula estimation for heteroscedastic extremes
                </td>
            </tr>
            <tr>
                <td class="abstract">
                    Chen Zhou<br>
                    Erasmus University Rotterdam<br>
                    zhou@ese.eur.nl
                </td>
            </tr>
            <tr>
                <td class="abstract">
                    Consider independent multivariate random vectors which follow the same copula, but where each marginal distribution is allowed to be non-stationary. This non-stationarity is for each marginal governed by a scedasis function (see Einmahl et al. (2016)) that is the same for all marginals. We establish the asymptotic normality of the usual rank-based estimator of the stable tail dependence function, or, when specialized to bivariate random vectors, the corresponding estimator of the tail copula. Remarkably, the heteroscedastic marginals do not affect the limiting process. Next, under a bivariate setup, we develop nonparametric tests for testing whether the scedasis functions are the same for both marginals. Detailed simulations show the good performance of the estimator for the tail dependence coefficient as well as that of the new tests. In particular, novel asymptotic confidence intervals for the tail dependence coefficient are presented and their good finite-sample behavior is shown. Finally an application to the S&P500 and Dow Jones indices reveals that their scedasis functions are about equal and that they exhibit strong tail dependence. 
                </td>
            </tr>

        </table>
    </div>

    <button type="button" class="collapsible">Tentative: Recent Advances in Neuroimaging Analysis</button>
    <div class="content">
        <table id="PUTSPEAKERNAMEHERE">
            <tr>
                <td class="organizer">
                    Lexin Li (Organizer)
                </td>
            </tr>
            <tr>
                <td class="speaker">
                    Hernando Ombao
                </td>
            </tr>
            <tr>
                <td class="speaker">
                    Jaroslaw Harezlak
                </td>
            </tr>
            <tr>
                <td class="speaker">
                    Haoda Fu
                </td>
            </tr>
            <tr>
                <td class="speaker">
                    Lexin Li
                </td>
            </tr>

            <tr>
                <td class="title">
                    Overview of Functional Dependence in Brain Networks
                </td>
            </tr>
            <tr>
                <td class="abstract">
                    Hernando Ombao<br>
                    Statistics Program, 
                    King Abdullah University of Science and Technology<br>
                    hernando.ombao@kaust.edu.sa
                </td>
            </tr>
            <tr>
                <td class="abstract">
                    Brain activity is complex. A full understanding of brain activity requires careful study of its multi-scale spatial-temporal organization (from neurons to regions of interest; and from transient events to long-term temporal dynamics). Motivated by these challenges, we will explore some characterizations of dependence between components of a brain network. This is potentially interesting because alterations in functional brain connectivity are associated with mental and neurological diseases. In this talk, we provide an overview of functional dependence measures. We present a general framework for exploring dependence through the oscillatory activities derived from each component of the tine series. The talk will draw connections of this framework to some of the classical notions of spectral dependence such as coherence, partial coherence, and dual-frequency coherence. Moreover, this framework provides a starting point for exploring potential non-linear cross-frequency interactions. These interactions include the impact of phase of one oscillatory activity in one component on the amplitude of another oscillation. The proposed approach captures lead-lag relationships and hence can be used as a general framework for spectral causality. Under this framework, we will also present some recent work on inference using spectral mutual information and entropy measures. This is joint work with Marco Pinto (UC Irvine), Paolo Redondo (KAUST) and Raphael Huser (KAUST).
                </td>
            </tr>

            <tr>
                <td class="title">
                    Novel penalized regression method applied to study the association of brain functional connectivity and alcohol drinking
                </td>
            </tr>
            <tr>
                <td class="abstract">
                    Jaroslaw (Jarek) Harezlak, Ph.D.<br>
                    Department of Epidemiology and Biostatistics, School of Public Health-Bloomington, 
                    Indiana University, Bloomington, IN<br>
                    harezlak@iu.edu                    
                </td>
            </tr>
            <tr>
                <td class="abstract">
                    The intricate associations between brain functional connectivity and clinical outcomes are difficult to estimate. Common approaches used do not account for the interrelated connectivity patterns in the functional connectivity (FC) matrix, which can jointly and/or synergistically affect the outcomes. In our application of a novel penalized regression approach called SpINNEr (Sparsity Inducing Nuclear Norm Estimator), we identify brain FC patterns that predict drinking outcomes. Results dynamically summarized in the R shiny app indicate that this scalar-on-matrix regression framework via the SpINNEr approach uncovers numerous reproducible FC associations with alcohol consumption. 
                </td>
            </tr>

            <tr>
                <td class="title">
                    LLM Is Not All You Need. Generative AI on Smooth Manifolds 
                </td>
            </tr>
            <tr>
                <td class="abstract">
                    Haoda Fu, Ph.D.<br>
                    Associate Vice President, AI/Machine Learning, AADS, Eli Lilly<br>
                    fu_haoda@lilly.com
                </td>
            </tr>
            <tr>
                <td class="abstract">
                    Generative AI is a rapidly evolving technology that has garnered significant interest lately. In this presentation, we'll discuss the latest approaches, organizing them within a cohesive framework using stochastic differential equations to understand complex, high-dimensional data distributions. We'll highlight the necessity of studying generative models beyond Euclidean spaces, considering smooth manifolds essential in areas like robotics and medical imagery, and for leveraging symmetries in the de novo design of molecular structures. Our team's recent advancements in this blossoming field, ripe with opportunities for academic and industrial collaborations, will also be showcased.
                </td>
            </tr>

            <tr>
                <td class="title">
                    Kernel Ordinary Differential Equations
                </td>
            </tr>
            <tr>
                <td class="abstract">
                    Lexin Li<br>
                    Professor, Department of Biostatistics and Epidemiology & Helen Wills Neuroscience Institute, University of California, Berkeley<br>
                    lexinli@berkeley.edu
                </td>
            </tr>
            <tr>
                <td class="abstract">
                    Ordinary differential equation (ODE) is widely used in modeling biological and physical processes in science. In this talk, we propose a new reproducing kernel-based approach for estimation and inference of ODE given noisy observations. We do not assume the functional forms in ODE to be known, or restrict them to be linear or additive, and we allow pairwise interactions. We perform sparse estimation to select individual functionals, and construct confidence intervals for the estimated signal trajectories. We establish the estimation optimality and selection consistency of kernel ODE under both the low-dimensional and high-dimensional settings, where the number of unknown functionals can be smaller or larger than the sample size. Our proposal builds upon the smoothing spline analysis of variance (SS-ANOVA) framework, but tackles several important problems that are not yet fully addressed, and thus extends the scope of existing SS-ANOVA as well. We demonstrate the efficacy of our method through numerous ODE examples.
                </td>
            </tr>

        </table>
    </div>

    <button type="button" class="collapsible">Joint Modeling of Complex Survival Data</button>
    <div class="content">
        <table id="PUTSPEAKERNAMEHERE">
            <tr>
                <td class="organizer">
                    Xinyuan Song (Organizer)
                </td>
            </tr>
            <tr>
                <td class="speaker">
                    Xingqiu Zhao
                </td>
            </tr>
            <tr>
                <td class="speaker">
                    Liming Xiang
                </td>
            </tr>
            <tr>
                <td class="speaker">
                    Jun Ma
                </td>
            </tr>
            <tr>
                <td class="speaker">
                    Xinyuan Song
                </td>
            </tr>

            <tr>
                <td class="title">
                    Deep Nonparametric Inference for Conditional Hazard Function
                </td>
            </tr>
            <tr>
                <td class="abstract">
                    Xingqiu Zhao<br> 
                    The Hong Kong Polytechnic University<br>
                    xingqiu.zhao@polyu.edu.hk
                </td>
            </tr>
            <tr>
                <td class="abstract">
                    We propose a novel deep learning approach to nonparametric statistical inference for the conditional hazard function of survival time with right-censored data. We use a deep neural network (DNN) to approximate the logarithm of a conditional hazard function given covariates and obtain a DNN likelihood-based estimator of the conditional hazard function. Such an estimation approach grants model flexibility and hence relaxes structural and functional assumptions on conditional hazard or survival functions. We establish the consistency, convergence rate, and functional asymptotic normality of the proposed estimator. Subsequently, we develop new one-sample tests for goodness-of-fit evaluation and two-sample tests for treatment comparison. Both simulation studies and real application analysis show superior performances of the proposed estimators and tests in comparison with existing methods. 
                </td>
            </tr>

            <tr>
                <td class="title">
                    Multiple Imputation for Flexible Modelling of Interval-censored Data with Covariates Subject to Missingness and Detection Limits 
                </td>
            </tr>
            <tr>
                <td class="abstract">
                    Liming Xiang<br>
                    Nanyang Tech University<br>
                    LMXiang@ntu.edu.sg
                </td>
            </tr>
            <tr>
                <td class="abstract">
                    Interval-censored failure time data is popular in biomedical studies when a failure time is not observed exactly but only known to lie in an interval obtained from a sequence of examination times. The presence of covariates subject to missingness and detection limits poses challenges for regression analysis of interval-censored data and necessitates an eﬀective statistical method. We propose a novel multiple imputation approach via rejection sampling for analysis of such data under semiparametric transformation models. Our proposal alleviates strong dependence of the usual imputation methods on the choice of imputation models and yields consistently and asymptotically normal estimators of the regression parameters. Simulation studies demonstrate that the proposed approach is flexible and leads to more efficient estimation than the complete analysis and augmented inverse probability weighting analysis in various practical situations. Finally, we apply the proposed approach to an Alzheimer’s disease data set that motivates this study. 
                </td>
            </tr>

            <tr>
                <td class="title">
                    Joint modelling of longitudinal covariates and partly-interval censored survival data - a penalized likelihood approach
                </td>
            </tr>
            <tr>
                <td class="abstract">
                    Jun Ma<br>
                    Macquarie University<br>
                    jun.ma@mq.edu.au
                </td>
            </tr>
            <tr>
                <td class="abstract">
                    This talk will focus on a joint modelling of longitudinal covariates and partly interval censored time-to-event data. Longitudinal time-varying covariates play a crucial role in achieving accurate dynamic predictions using a survival regression model. However, these covariates are often measured at limited time points and may contain measurement errors. Moreover, they are usually specific to each individual. On the other hand, the event times of interest are often interval-censored. Accounting for all these factors is essential when constructing a survival model. We will present a new approach for joint modelling of the longitudinal time-varying covariates and the time-to-event Cox model, where the latter is subject to interval censoring. We will develop a novel maximum penalized likelihood approach for estimation of all the model parameters including the random effects. A profile likelihood is used to obtain the covariance matrix of the estimated parameters.    
                </td>
            </tr>

            <tr>
                <td class="title">
                    Bayesian tree-based heterogeneous mediation analysis with a time-to-event outcome
                </td>
            </tr>
            <tr>
                <td class="abstract">
                    Xinyuan Song<br>
                    Chinese University of Hong Kong<br>
                    xysong@sta.cuhk.edu.hk
                </td>
            </tr>
            <tr>
                <td class="abstract">
                    Mediation analysis aims at quantifying and explaining the underlying causal mechanism between an exposure and an outcome of interest. In the context of survival analysis, mediation models have been widely used to achieve causal interpretation for the direct and indirect effects on the survival of interest. Although heterogeneity in treatment effect is drawing increasing attention in biomedical studies, none of the existing methods have accommodated the presence of heterogeneous causal pathways pointing to a time-to-event outcome. In this study, we consider a heterogeneous mediation analysis for survival data based on a Bayesian tree-based Cox proportional hazards model with shared topologies. Under the potential outcomes framework, individual-specific conditional direct and indirect effects are derived on the scale of the logarithm of hazards, survival probability, and restricted mean survival time. A Bayesian approach with efficient sampling strategies is developed to estimate the conditional causal effects through the Monte Carlo implementation of the mediation formula. Simulation studies show the satisfactory performance of the proposed method. The proposed model is then applied to an HIV dataset extracted from the ACTG175 study to demonstrate its usage in detecting heterogeneous causal pathways.
                </td>
            </tr>

        </table>
    </div>
    

    <button type="button" class="collapsible">Analysis of data with multiple treatments and mixed outcomes</button>
    <div class="content">
        <table id="PUTSPEAKERNAMEHERE">
            <tr>
                <td class="organizer">
                    Lan Luo (Organizer)
                </td>
            </tr>
            <tr>
                <td class="speaker">
                    Emily Hector
                </td>
            </tr>
            <tr>
                <td class="speaker">
                    Lan Luo
                </td>
            </tr>
            <tr>
                <td class="speaker">
                    Ling Zhou
                </td>
            </tr>
            <tr>
                <td class="speaker">
                    Liangyuan Hu
                </td>
            </tr>

            <tr>
                <td class="title">
                    Turning the data-integration dial: efficient inference from different data sources
                </td>
            </tr>
            <tr>
                <td class="abstract">
                    Emily Hector<br>
                    University of North Carolina, Chapel Hill
                </td>
            </tr>
            <tr>
                <td class="abstract">
                    A fundamental aspect of statistics is the integration of data from different sources. Classically, Fisher and others were focused on how to integrate homogeneous sets of data. More recently, the question of if data sets from different sources should be integrated is becoming more relevant. The current literature treats this as a yes/no question: integrate or don't. Here we take a different approach, motivated by information-sharing principles coming from the shrinkage estimation literature. In particular, we deviate from the binary, yes/no perspective and propose a dial parameter that controls the extent to which two data sources are integrated. How far this dial parameter should be turned is shown to depend on the informativeness of the different data sources as measured by Fisher information. This more-nuanced data integration framework leads to relatively simple parameter estimates and valid tests/confidence intervals. We demonstrate both theoretically and empirically that setting the dial parameter according to our recommendation leads to more efficient estimation compared to other binary data integration schemes.
                </td>
            </tr>

            <tr>
                <td class="title">
                    Efficient quantile covariate adjusted response adaptive experiments
                </td>
            </tr>
            <tr>
                <td class="abstract">
                    Lan Luo<br>
                    Assistant Professor, Department of Biostatistics and Epidemiology, Rutgers School of Public Health<br>
                    ll1118@sph.rutgers.edu
                </td>
            </tr>
            <tr>
                <td class="abstract">
                    In program evaluation studies, understanding the heterogeneous distributional impacts of a program beyond the average effect is crucial. Quantile treatment effect (QTE) provides a natural measure to capture such heterogeneity. While much of the existing work for estimating QTE has focused on analyzing observational data based on untestable causal assumptions, little work has gone into designing randomized experiments specifically for estimating QTE. In this talk, we propose two covariate adjusted response adaptive design strategies–fully adaptive designs and multi-stage designs–to efficiently estimate the QTE. We demonstrate that the QTE estimator obtained from our designs attains the optimal variance lower bound from a semiparametric theory perspective, which does not impose any parametric assumptions on underlying data distributions. Moreover, we show that using continuous covariates in multi-stage designs can improve the precision of the estimated QTE compared to the classical fully adaptive setting. We illustrate the finite-sample performance of our designs through Monte Carlo experiments and one synthetic case study on charitable giving. Our proposed designs offer a new approach to conducting randomized experiments to estimate QTE, which can have important implications for policy and program evaluation.
                </td>
            </tr>

            <tr>
                <td class="title">
                    High-dimensional subgroup learning for multiple mixed outcome 
                </td>
            </tr>
            <tr>
                <td class="abstract">
                    Ling Zhou<br>
                    Southwestern University of Finance and Economics<br>
                    zhouling@swufe.edu.cn
                </td>
            </tr>
            <tr>
                <td class="abstract">
                    In survey research, it is interesting to infer the grouped association patterns between risk factors and questionnaire responses, where the grouping is shared across multiple response variables that jointly capture one’s underlying status. In particular, based on a survey study named the China Health and Retirement Survey (CHRS), our aim is to identify the important risk factors that are simultaneously associated with the health and well-being of senior adults. While earlier studies have pointed to several known risk factors, heterogeneity in the outcome-risk factor association exists, motivating us to analyze this data through the lens of subgroup analysis. We devise a subgroup analysis procedure that models a multiple mixed outcome which describe one’s general health and well-being, while tackling additional challenges that have arisen in our data analysis, including high-dimensionality, collinearity, and weak signals in covariates. Computationally, we propose an efficient algorithm that alternately updates a set of estimating equations and likelihood functions. Theoretically, we establish the asymptotic consistency and normality of the proposed estimators. The validity of our proposal is corroborated by simulation experiments. An application of the proposed method to the CHRS data identifies caring for grandchildren as a new risk factor for poor physical and mental health.       
                </td>
            </tr>

            <tr>
                <td class="title">
                    Estimating the causal effect of multiple intermittent treatments on censored survival outcomes
                </td>
            </tr>
            <tr>
                <td class="abstract">
                    Liangyuan Hu<br>
                    Rutgers University<br>
                    lh707@sph.rutgers.edu
                </td>
            </tr>
            <tr>
                <td class="abstract">
                    To draw real-world evidence about the comparative effectiveness of multiple time-varying treatments on patient survival, we develop a joint marginal structural survival model and a novel weighting strategy to account for time-varying confounding and censoring. Our methods formulate complex longitudinal treatments with multiple start/stop switches as the recurrent events with discontinuous intervals of treatment eligibility. We derive the weights in continuous time to handle a complex longitudinal dataset without the need to discretize or artificially align the measurement times. We further use machine learning models designed for censored survival data with time-varying covariates and the kernel function estimator of the baseline intensity to efficiently estimate the continuous-time weights. Our simulations demonstrate that the proposed methods provide better bias reduction and nominal coverage probability when analyzing observational longitudinal survival data with irregularly spaced time intervals, compared to conventional methods that require aligned measurement time points. We apply the proposed methods to a large-scale COVID-19 dataset to estimate the causal effects of several COVID-19 treatments on the composite of in-hospital mortality and ICU admission.
                </td>
            </tr>
        </table>
    </div>
    
    <button type="button" class="collapsible">TBD</button>
    <div class="content">
        <table id="PUTSPEAKERNAMEHERE">
            <tr>
                <td class="organizer">
                    Ying Wei (Organizer)
                </td>
            </tr>
            <tr>
                <td class="speaker">
                    Shuang Wang
                </td>
            </tr>
            <tr>
                <td class="speaker">
                    Rui Duan
                </td>
            </tr>
            <tr>
                <td class="speaker">
                    Yanyuan Ma
                </td>
            </tr>
            <tr>
                <td class="speaker">
                    Ying Wei
                </td>
            </tr>

            <tr>
                <td class="title">
                    PartIES: a disease subtyping framework with Partition-level Integration using diffusion-Enhanced Similarities from Multi-omics Data
                </td>
            </tr>
            <tr>
                <td class="abstract">
                    Yuqi Miao<sup>1</sup>, Huang Xu<sup>2</sup>, Shuang Wang<sup>1*</sup><br>
                    1. Department of Biostatistics, Columbia University, New York New York USA<br>
                    2. Department of Statistics, University of Science and Technology of China, Hefei, Anhui, P.R. China<br>
                    sw2206@cumc.columbia.edu
                </td>
            </tr>
            <tr>
                <td class="abstract">
                    Integrating multi-omics data helps identify disease subtypes. Many similarity-based clustering methods were developed for disease subtyping using multi-omics data, with many of them focusing on extracting common clustering structures across multiple types of omics data, thus are not meant to preserve specific clustering structures within each omics data type. Moreover, clustering performance of similarity-based methods are known to be affected by how accurate similarity measures are. In this paper, we proposed PartIES, a Partition-level Integration using diffusion-Enhanced Similarities (PartIES) to perform disease subtyping using multi-omics data. We propose to use diffusion to reduce noises in similarity/kernel matrices, and partition individual diffusion-enhanced similarity matrices before integration and learn the integrative similarity structure adaptively on the partition level. Simulation studies showed that the diffusion step enhances clustering accuracy, and PartIES outperforms other competing methods, especially when omics data types provide different clustering structures. Using mRNA, lncRNA, miRNA expression data, DNA methylation data and mutation data from The Cancer Genome Atlas project (TCGA), PartIES identified subtypes in bladder urothelial carcinoma (BLCA) and thyroid carcinoma (THCA) that most significantly differentiate patient survival among all methods. To provide the biological meaning of the identified cancer subtypes, we further mapped subtype-differentiated omics features to the protein-protein interaction (PPI) network to identify important interacting cancer genes and compared the activities of cancer-related pathways across subtypes.
                </td>
            </tr>

            <tr>
                <td class="title">
                    Robust angle-based transfer learning in high dimensions
                </td>
            </tr>
            <tr>
                <td class="abstract">
                    Rui Duan, PhD<br>
                    Assistant Professor of Biostatistics, Harvard T.H. Chan School of Public Health<br>
                    Email: rduan@hsph.harvard.edu
                </td>
            </tr>
            <tr>
                <td class="abstract">
                    Transfer learning aims to improve the performance of a target model by leveraging data from related source populations, which is known to be especially helpful in cases with insufficient target data. In this paper, we study the problem of how to train a high-dimensional ridge regression model using limited target data and existing regression models trained in heterogeneous source populations. We consider a practical setting where only the parameter estimates of the fitted source models are accessible, instead of the individual-level source data. Under the setting with only one source model, we propose a novel flexible angle-based transfer learning (angleTL) method, which leverages the concordance between the source and the target model parameters. We show that angleTL unifies several benchmark methods by construction, including the target-only model trained using target data alone, the source model fitted on source data, and distance-based transfer learning method that incorporates the source parameter estimates and the target data under a distance-based similarity constraint. We also provide algorithms to effectively incorporate multiple source models accounting for the fact that some source models may be more helpful than others. Our high-dimensional asymptotic analysis provides interpretations and insights regarding when a source model can be helpful to the target model, and demonstrates the superiority of angleTL over other benchmark methods. We perform extensive simulation studies to validate our theoretical conclusions and show the feasibility of applying angleTL to transfer existing genetic risk prediction models across multiple biobanks.
                </td>
            </tr>

            <tr>
                <td class="title">
                    Doubly Flexible Estimation under Label Shift
                </td>
            </tr>
            <tr>
                <td class="abstract">
                    Yanyuan Ma<br>
                    Pennsylvania State University<br>
                    yanyuanma@gmail.com
                </td>
            </tr>
            <tr>
                <td class="abstract">
                    In studies ranging from clinical medicine to policy research, complete data are usually available from a population P, but the quantity of interest is often sought for a related but different population Q which only has partial data. In this paper, we consider the setting that both outcome Y and covariate X are available from P whereas only X is available from Q, under the so-called label shift assumption, i.e., the conditional distribution of X given Y remains the same across the two populations. To estimate the parameter of interest in population Q via leveraging the information from population P, the following three ingredients are essential: (a) the common conditional distribution of X given Y, (b) the regression model of Y given X in population P, and (c) the density ratio of the outcome Y between the two populations. We propose an estimation procedure that only needs some standard nonparametric regression technique to approximate the conditional expectations with respect to (a), while by no means needs an estimate or model for (b) or (c); i.e., doubly flexible to the possible model misspecifications of both (b) and (c). This is conceptually different from the well-known doubly robust estimation in that, double robustness allows at most one model to be misspecified whereas our proposal here can allow both (b) and (c) to be misspecified. This is of particular interest in our setting because estimating (c) is difficult, if not impossible, by virtue of the absence of the Y-data in population Q. Furthermore, even though the estimation of (b) is sometimes off-the-shelf, it can face curse of dimensionality or   computational challenges. We develop the large sample theory for the proposed estimator, and examine its finite-sample performance through simulation studies as well as an application to the MIMIC-III database.
                </td>
            </tr>

            <tr>
                <td class="title">
                    A Double Projection Approach for Safe and Efficient Semi-Supervised Data-Fusion
                </td>
            </tr>
            <tr>
                <td class="abstract">
                    Ying Wei<br>
                    Columbia University<br>
                    yw2148@cumc.columbia.edu
                </td>
            </tr>
            <tr>
                <td class="abstract">
                    Advances in data collection and transmission technologies have made larger amounts of data readily available. However, there are differences in the data collection capabilities of different data centers, or there are inevitable data missing. Many previous approaches to handling missing information have solely focused on either missing predictors or missing responses. In this paper, we will consider both types of missing and incorporate more information by projecting score functions into subsets, thus proposing algorithms that have ensured efficiency relative to the complete-case analysis. By generalizing the algorithm of this paper, it is promising to be able to handle more complex missing data structures in the future. This is joint work with Molei Liu, Yiming Li and Sean Yang. 
                </td>
            </tr>

        </table>
    </div>
    

    <button type="button" class="collapsible">Analysis of multi-dimensional correlated data</button>
    <div class="content">
        <table id="PUTSPEAKERNAMEHERE">
            <tr>
                <td class="organizer">
                    Peter Song (Organizer)
                </td>
            </tr>
            <tr>
                <td class="speaker">
                    Annie Qu
                </td>
            </tr>
            <tr>
                <td class="speaker">
                    Heping Zhang
                </td>
            </tr>
            <tr>
                <td class="speaker">
                    Ji Zhu
                </td>
            </tr>
            <tr>
                <td class="speaker">
                    Jian Kang
                </td>
            </tr>

            <tr>
                <td class="title">
                    Optimal Individualized Treatment Rule for Combination Treatments under Budget Constraints
                </td>
            </tr>
            <tr>
                <td class="abstract">
                    Annie Qu <br>
                    University of California, Irvine <br>
                    aqu2@uci.edu

                </td>
            </tr>
            <tr>
                <td class="abstract">
                    The individualized treatment rule (ITR), which recommends an optimal treatment based on individual characteristics, has drawn considerable interest from many areas such as precision medicine, personalized education, and personalized marketing. Existing ITR estimation methods mainly adopt one of two or more treatments. However, a combination of multiple treatments could be more powerful in various areas. In this paper, we propose a novel Double Encoder Model (DEM) to estimate the individualized treatment rule for combination treatments. The proposed double encoder model is a nonparametric model which not only flexibly incorporates complex treatment effects and interaction effects among treatments, but also improves estimation efficiency via the parameter-sharing feature. In addition, we tailor the estimated ITR to budget constraints through a multi-choice knapsack formulation, which enhances our proposed method under restricted-resource scenarios. In theory, we provide the value reduction bound with or without budget constraints, and an improved convergence rate with respect to the number of treatments under the DEM. Our simulation studies show that the proposed method outperforms the existing ITR estimation in various settings. We also demonstrate the superior performance of the proposed method in PDX data that recommends optimal combination treatments to shrink the tumor size of the colorectal cancer.
                </td>
            </tr>

            <tr>
                <td class="title">
                    Tensor quantile regression with applications in brain imaging data analysis
                </td>
            </tr>
            <tr>
                <td class="abstract">
                    Heping Zhang<br>
                    Yale University<br>
                    heping.zhang@yale.edu
                </td>
            </tr>
            <tr>
                <td class="abstract">
                    Neuroimaging studies through analysis of magnetic resonance imaging (MRI) data are important in our understanding of brain function. A critical technique in those studies is tensor regression models in which a scalar outcome is regressed against an array of images collectively called tensor. The high dimensionality of the tensor makes it necessary to reduce the dimension of the data through decomposition of the data as well as constrained optimalization by making use of the imaging data structures. The non-normality of the response also calls for attention to the use of quantile regression techniques.  In this present, we will discuss relevant statistical techniques in tensor quantile regression and an application in brain imaging data analysis.   
                </td>
            </tr>

            <tr>
                <td class="title">
                    A Latent Space Model for Hypergraphs with Diversity and Heterogeneous Popularity
                </td>
            </tr>
            <tr>
                <td class="abstract">
                    Ji Zhu<br>
                    Susan A. Murphy Collegiate Professor, Associate Chair for Graduate Programs, Department of Statistics, University of Michigan, Ann Arbor<br>
                    jizhu@umich.edu
                </td>
            </tr>
            <tr>
                <td class="abstract">
                    While relations among individuals make an important part of data with scientific and business interests, existing statistical modeling of relational data has mainly been focusing on dyadic relations, i.e., those between two individuals. This work addresses the less studied, though commonly encountered, polyadic relations that can involve more than two individuals. In particular, we propose a new latent space model for hypergraphs using determinantal point processes, which is driven by the diversity within hyperedges and each node's popularity. This model mechanism is in contrast to existing hypergraph models, which are predominantly driven by similarity rather than diversity. Additionally, the proposed model accommodates broad types of hypergraphs, with no restriction on the cardinality and multiplicity of hyperedges. Consistency and asymptotic normality of the maximum likelihood estimates of the model parameters have been established. The proof is challenging, owing to the special configuration of the parameter space. Simulation studies and an application to the What's Cooking data show the effectiveness of the proposed model.
                </td>
            </tr>

            <tr>
                <td class="title">
                    Bayesian methods for brain-computer interfaces
                </td>
            </tr>
            <tr>
                <td class="abstract">
                    Jian Kang <br>
                    University of Michigan<br>
                    jiankang@umich.edu
                </td>
            </tr>
            <tr>
                <td class="abstract">
                    A brain-computer interface (BCI) is a system that translates brain activity into commands to operate technology. BCIs help people with disabilities use technology for communication. A common design for an electroencephalogram (EEG) BCI relies on the classification of the P300 event-related potential (ERP), which is a response elicited by the rare occurrence of target stimuli among common non-target stimuli. Existing studies have focused on constructing the ERP classifiers, but few provide insights into the underlying mechanism of the neural activity. In this talk, I will discuss several new Bayesian methods for analyzing brain signals from BCI systems based on Gaussian Processes (GP). Our proposed methods can make statistical inferences about the spatial-temporal differences and dependence of the neural activity in response to external stimuli, which provides statistical evidence of P300 ERP responses and helps design user-specific profiles for efficient BCIs.  Our inference results demonstrate the importance of ERPs from several brain regions for P300 speller performance. The robustness of our analysis is justified by cross-participant comparisons and extensive simulations. 
                </td>
            </tr>

        </table>
    </div>

    <button type="button" class="collapsible">Statistical Methods for Metagenomic Data</button>
    <div class="content">
        <table id="PUTSPEAKERNAMEHERE">
            <tr>
                <td class="organizer">
                    Gen Li (Organizer)
                </td>
            </tr>
            <tr>
                <td class="speaker">
                    Hongzhe Li
                </td>
            </tr>
            <tr>
                <td class="speaker">
                    Huilin Li
                </td>
            </tr>
            <tr>
                <td class="speaker">
                    Zhigang Li
                </td>
            </tr>
            <tr>
                <td class="speaker">
                    Gen Li
                </td>
            </tr>

            <tr>
                <td class="title">
                    Transfer Learning with Random Coefficient Ridge Regression for Microbiome Applications
                </td>
            </tr>
            <tr>
                <td class="abstract">
                    Hongzhe Li<br>
                    University of Pennsylvannia<br>
                    hongzhe@pennmedicine.upenn.edu
                </td>
            </tr>
            <tr>
                <td class="abstract">
                    Ridge regression with random coefficients provides an important alternative to fixed coefficients regression in high dimensional setting when the effects are expected to be small but not zeros. Such models are particularly appropriate for microbiome-based prediction. This paper considers estimation and prediction of random coefficient ridge regression in the setting of transfer learning, where in addition to observations from the target model, source samples from different but possibly related regression models are available. The informativeness of the source model to the target model can be quantified by the correlation between the regression coefficients. This paper proposes two estimators of regression coefficients of the target model as the weighted sum of the ridge estimates of both target and source models, where the weights can be determined by minimizing the limiting estimation risk or prediction risk.  Using random matrix theory, the limiting values of the optimal weights are derived under the setting when p/n→γ, where p is the number of the predictors and n is the sample size, which leads to an explicit expression of the estimation or prediction risks. We present results for several microbiome-based disease prediction, including IBD and colon cancer. 
                </td>
            </tr>

            <tr>
                <td class="title">
                    Joint Modeling of Longitudinal Microbiome Data and Survival outcome.
                </td>
            </tr>
            <tr>
                <td class="abstract">
                    Huilin Li<br>
                    New York Univesity<br>
                    Huilin.Li@nyulangone.org
                </td>
            </tr>
            <tr>
                <td class="abstract">
                    Recently more and more longitudinal microbiome studies are conducted to identify candidate microbes as biomarkers for the disease prognosis. We propose a novel joint modeling framework JointMM for longitudinal microbiome and time-to-event data to investigate the effect of dynamic changes of microbiome abundance profile on disease onset. JointMM comprises of two sub-models, i.e., the zero-inflated scaled-Beta mixed-effects regression sub-model aimed at depicting the temporal structure of microbial abundances among subjects; and the survival sub-model to characterize the occurrence of disease and its relationship with microbiome abundances changes. JointMM is specifically designed to handle the zero-inflated and highly skewed longitudinal microbiome abundance data and exhibits better interpretability that JointMM can examine whether the temporal microbial presence/absence pattern and/or the abundance dynamics would alter the time to disease onset. Comprehensive simulations and real data analyses demonstrated the statistical efficiency of JointMM compared with competing methods.
                </td>
            </tr>

            <tr>
                <td class="title">
                    Estimating equations with inverse probability weighting for microbiome analysis
                </td>
            </tr>
            <tr>
                <td class="abstract">
                    Zhigang Li<br>
                    University of Florida<br>
                    zhigang.li@ufl.edu
                </td>
            </tr>
            <tr>
                <td class="abstract">
                    Human microbiome data is collected in many research studies to investigate the role of microbiome in association with diseases or conditions. Sequencing technologies including 16S rRNA sequencing and metagenome shotgun sequencing are commonly used for quantifying microbiome data. However, it remains challenging to appropriately analyze microbiome data due to its unique features such as zero-inflated structure and compositional structure. We develop a novel approach to analyze microbiome data for differential abundance analyses or regression analyses. This approach employes inverse probability weighting techniques to account for the mixture of true and false zeros. GEE is used to account for the complicated inter-taxa correlation structure. The method does not require imputing zeros with a positive value for the data analysis. It has a good performance in comparison with existing methods in the simulation study. Application of the new approach in a real data set is also presented.
                </td>
            </tr>

            <tr>
                <td class="title">
                    Analysis of Microbiome Differential Abundance by Pooling Tobit Models
                </td>
            </tr>
            <tr>
                <td class="abstract">
                    Gen Li, PhD<br>
                    Associate Professor, Department of Biostatistics, School of Public Health, University of Michigan, Ann Arbor<br>
                    ligen@umich.edu
                </td>
            </tr>
            <tr>
                <td class="abstract">
                    Differential abundance analysis identifies microbiome taxa whose abundances differ between two or more conditions. Compositionality and sparsity of metagenomics sequencing data pose statistical challenges. We propose ADAPT (Analysis of Microbiome Differential Abundance by Pooling Tobit Models) as a solution. Count ratios between taxa satisfy subcompositional coherence. Zero counts can be regarded as left-censored at one. The tobit model is suitable for modeling left-censored count ratios. ADAPT first fits tobit models to relative abundances of individual taxa. It then selects a subset of non-differentially abundant taxa as the reference taxa set based on the estimated effect sizes and the distribution of p-values. Finally, tobit models for the count ratios between individual taxa and the reference taxa set reveal differentially abundant taxa. Simulation studies show that ADAPT has higher power than alternative methods while controlling false discovery rates. Application of ADAPT to early childhood dental caries data reveals differentially abundant oral bacteria species and functional genes between the saliva samples of children with and without dental caries. 
                </td>
            </tr>

        </table>
    </div>

    <button type="button" class="collapsible">TBD</button>
    <div class="content">
        <table id="PUTSPEAKERNAMEHERE">
            <tr>
                <td class="organizer">
                    Shuangge Ma (Organizer)
                </td>
            </tr>
            <tr>
                <td class="speaker">
                    Hao Mei
                </td>
            </tr>
            <tr>
                <td class="speaker">
                    Yuan Huang
                </td>
            </tr>
            <tr>
                <td class="speaker">
                    Shuangge Ma
                </td>
            </tr>
            <tr>
                <td class="speaker">
                    Ai-Ling Hour
                </td>
            </tr>

            <tr>
                <td class="title">
                    Clinical Human Disease Networks with Healthcare Administrative Claims Data
                </td>
            </tr>
            <tr>
                <td class="abstract">
                    Hao Mei<br>
                    Renmin University of China<br>
                    hao.mei@ruc.edu.cn
                </td>
            </tr>
            <tr>
                <td class="abstract">
                    Clinical treatment outcomes are the quality and cost targets that healthcare providers aim to improve. Most existing outcome analysis focuses on a single disease or all diseases combined, which ignores the complex interconnections among diseases. Motivated by the success of molecular and phenotypic human disease networks (HDNs), we develop clinical HDNs that describes the interconnections among diseases in terms of multiple clinical treatment outcomes. In this framework, one node represents one disease, and two nodes are linked with an edge if their outcomes are conditionally dependent. Along this direction, we also develop a time-dependent clinical HDN that investigate temporal variation of disease interconnection from a clinical point of view. Our data experiments validate the performance of the proposed models in identifying correct edges. Analyzing key network properties, such as connectivity, module/hub, and temporal variation, using healthcare administrative claims data, the findings are not only biomedically sensible, but also uncover information that are less/not investigated in the literature. Overall, clinical HDNs can provide additional insight into diseases’ properties and their interconnections and assist more efficient disease management and health-care resources allocation.
                </td>
            </tr>

            <tr>
                <td class="title">
                    TBD
                </td>
            </tr>
            <tr>
                <td class="abstract">
                    Yuan Huang<br>
                    Yale University<br>
                    yuan.huang@yale.edu
                </td>
            </tr>
            <tr>
                <td class="abstract">
                    Traditional mediation analysis methods have been limited to handling only a small number of mediators, posing significant challenges when dealing with high-dimensional mediators. These challenges are further compounded by the intricate relationships introduced by confounding variables. To effectively address these issues, we introduce an approach called DP2LM (Deep neural network-based Penalized Partially Linear Mediation). This approach incorporates deep neural network techniques to account for nonlinear effects in confounders and utilizes the penalized partially linear model to accommodate high dimensionality. Unlike most existing works that concentrate on mediator selection, our method prioritizes estimation and inference on mediation effects. We will present its performance under simulation studies and its application to real-world data. Additionally, we will discuss some important considerations and potential limitations when utilizing this approach.
                </td>
            </tr>

            <tr>
                <td class="title">
                    Heterogeneous Network Analysis of Disease Clinical Treatment Measures via Mining Electronic Medical Record Data 
                </td>
            </tr>
            <tr>
                <td class="abstract">
                    Shuangge Ma <br>
                    Department of Biostatistics, Yale School of Public Health <br>
                    Shuangge.ma@yale.edu 
                </td>
            </tr>
            <tr>
                <td class="abstract">
                    The analysis of clinical treatment measures has been extensively conducted and can facilitate more effective resource management and planning and also assist better understanding siseases. Most of the existing analyses have been focused on a single disease or a large number of diseases combined. Partly motivated by the successes of gene-centric and phenotypic human disease network (HDN) research, there has been growing interest in the network analysis of clinical treatment measures. However, the existing studies have been limited by a lack of attention to heterogeneity and relevant covariates, ineffectiveness of methods, and low data quality. In this study, our goal is to mine the Taiwan National Health Insurance Research Database (NHIRD), a large population-level electronic medical record (EMR) database, and construct HDNs for number of outpatient visits and medical cost. Significantly advancing from the existing literature, the proposed analysis accommodates heterogeneity and effects of covariates (for example, demographics). Additionally, the proposed method effectively accommodates the zero-inflation nature of data, Poisson distribution, high-dimensionality, and network sparsity. Computational and theoretical properties are carefully examined. Simulation demonstrates competitive performance of the proposed approach. In the analysis of NHIRD data, two and five subject groups are identified for outpatient visit and medical cost, respectively. The identified interconnections, hubs, and network modules are found to have sound implications.
                </td>
            </tr>

            <tr>
                <td class="title">
                    Few-shot learning of Tabular Medical Records with Large Language Models 
                </td>
            </tr>
            <tr>
                <td class="abstract">
                    Kai-Yuan Hsiao<sup>1,2</sup>, Wei-Shan Chang<sup>1,2</sup>, Ai-Ling Hour<sup>3*</sup>, Ben-Chang Shia<sup>1,2</sup><br> 
                    1 Artificial Intelligence Development Center, Fu Jen Catholic University, New Taipei City,
                    Taiwan<br>
                    2 Graduate Institute of Business Administration, College of Management, Fu Jen Catholic
                    University, New Taipei City, Taiwan<br>
                    3 Department of Life Science, Fu-Jen Catholic University, New Taipei City, Taiwan<br>
                </td>
            </tr>
            <tr>
                <td class="abstract">
                    The medical field is replete with abundant tabular data encompassing everything from patient records to results of clinical trials. Traditional approaches to the analysis of such data often involve complex statistical techniques, feature engineering, and conventional machine learning methods. However, the integration of large language models (LLMs) offers a transformative method for this analysis. This study examines the application of LLMs for zero-shot and few-shot classification of medical tabular data, employing techniques for generating additional feature information and natural language serialization of tabular data. In this study, the methodology encompasses the serialization of medical tabular data into natural language strings, complete with descriptions of the specific analytical tasks. For instance, tables detailing patient symptoms and diagnoses are transformed into formats readily interpretable by Large Language Models (LLMs). Where only a few examples are present, the generative capacity of LLMs is harnessed to bolster their comprehension of medical contexts. Iterative generation of additional, semantically meaningful features is based on the medical background of the dataset, with an investigation into the efficacy of the generated features. In the experimental process, besides testing large language models for downstream tasks, comparisons with traditional machine learning methods are made, with efforts to interpret the results, ensuring that medical professionals can understand and trust the findings.
                </td>
            </tr>

        </table>
    </div>

    <button type="button" class="collapsible">Tentative: Advance Development and Application of Joint modeling</button>
    <div class="content">
        <table id="PUTSPEAKERNAMEHERE">
            <tr>
                <td class="organizer">
                    Cheng Zheng (Organizer)
                </td>
            </tr>
            <tr>
                <td class="speaker">
                    Ying Zhang
                </td>
            </tr>
            <tr>
                <td class="speaker">
                    Cheng Zheng
                </td>
            </tr>
            <tr>
                <td class="speaker">
                    Ping Ma
                </td>
            </tr>
            <tr>
                <td class="speaker">
                    Danping Liu
                </td>
            </tr>

            <tr>
                <td class="title">
                    Semiparametric Inference for Misclassified Semi-Competing Risks Data under Gamma-Frailty Conditional Markov Model
                </td>
            </tr>
            <tr>
                <td class="abstract">
                    Ying Zhang<sup>*</sup>, Ruiqian Wu, and Giorgos Bakoyannis<br>
                    *Department of Biostatistics, University of Nebraska Medical Center<br>
                    ying.zhang@unmc.edu
                </td>
            </tr>
            <tr>
                <td class="abstract">
                    There has been increasing interest in semi-competing risks data modeling to jointly study disease progression and death for the illness-death problem. Identification of risk factors for the benchmark events will provide insight to detect the high-risk group according to personal-level characteristics, which is critical to develop a personalized prevention strategy to delay the progression from illness to death. However, in many applications, event ascertainment is incomplete, resulting in event misclassification that complicates the statistical inference with semi-competing risks data. In this work, we consider a Gamma frailty conditional Markov model to study the misclassified semi-competing risk data and propose a two-stage semiparametric maximum pseudo-likelihood estimation approach equipped with a pseudo-EM algorithm to make unbiased statistical inference. Extensive simulation studies show the proposed method is numerically stable and performs well even with a large amount of event misclassification. The method is applied to a multi-center HIV cohort study in East Africa to measure the impact of interruption of lifelong antiretroviral therapy (ART) on HIV mortality at the personal level.
                </td>
            </tr>

            <tr>
                <td class="title">
                    Investigating Multiple Causal Mechanisms with Multiple Mediators and Estimating Direct and Indirect Effects: A Joint Modeling Approach for Recurrent and Terminal Events 
                </td>
            </tr>
            <tr>
                <td class="abstract">
                    Cheng Zheng, PhD<br>
                    Associate Professor, Department of Biostatistics, University of Nebraska Medical Center<br>
                    cheng.zheng@unmc.edu
                </td>
            </tr>
            <tr>
                <td class="abstract">
                    Understanding the diverse causal mechanisms between primary exposure and outcomes has garnered significant interest in the social and medical fields. In the context of HIV patients, over 20 distinct opportunistic infections (OIs) present complex effects on the health trajectory and associated mortality. It is crucial to differentiate among these OIs to devise tailored strategies to enhance patients' survival and quality of life. However, existing statistical frameworks for studying causal mechanisms have limitations, either focusing on single mediators or lacking the ability to handle unmeasured confounding, especially for the survival outcomes. In this work, we propose a novel joint modeling approach that considers multiple recurrent events as mediators and survival endpoints as outcomes, relaxing the assumption of “sequential ignorability” by utilizing the shared random effect to handle unmeasured confounders. We assume the multiple mediators are not causally related to each other given observed covariates and the shared frailty. Simulation studies demonstrate good finite sample performance of our methods in estimating both model parameters and multiple mediation effects. We apply our approach to an AIDS study and evaluate the mediation effects of different types of OIs. We find that distinct pathways through the two treatments and CD4 counts impact overall survival via different types of recurrent opportunistic infections.
                </td>
            </tr>

            <tr>
                <td class="title">
                    Analyzing CITE-seq Data via a Quantum Algorithm
                </td>
            </tr>
            <tr>
                <td class="abstract">
                    Ping Ma<br>
                    UGA Distinguished Research Professor, Department of Statistics, University of Georgia<br>
                    pingma@uga.edu
                </td>
            </tr>
            <tr>
                <td class="abstract">
                    With the rapid development of quantum computers, researchers have shown quantum advantages in physics-oriented problems. Quantum algorithms tackling computational biology problems are still lacking. In this talk, I will demonstrate the quantum advantage of analyzing CITE-seq data. CITE-seq, a single-cell technology, enables researchers to simultaneously measure expressions of RNA and surface protein detected by antibody-derived tags (ADTs) in the same cells. CITE-seq data hold tremendous potential for elucidating RNA-ADT co-expression networks and identifying cell types effectively. However, both tasks are challenging since the best subset of ADTs needs to be identified from enormous candidate subsets.  To surmount the challenge, I will present a quantum algorithm for analyzing CITE-seq data. 
                </td>
            </tr>

            <tr>
                <td class="title">
                    Dynamic Risk Prediction for Cervical Precancer Screening with Continuous and Binary Longitudinal Biomarkers
                </td>
            </tr>
            <tr>
                <td class="abstract">
                    Danping Liu<br>
                    National Cancer Institute<br>
                    danping.liu@nih.gov
                </td>
            </tr>
            <tr>
                <td class="abstract">
                    Dynamic risk prediction that incorporates longitudinal measurements of biomarkers is useful in identifying high-risk patients for better clinical management. Our work is motivated by the prediction of cervical precancers. Currently, Pap cytology is used to identify HPV+ women at high-risk of cervical precancer, but cytology lacks accuracy and reproducibility. HPV DNA methylation is closely linked to the carcinogenic process and shows promise of improved risk stratification. We are interested in developing a dynamic risk model that uses all longitudinal biomarker information to improve precancer risk estimation. We propose a joint model to link both the continuous methylation biomarker and binary cytology biomarker to the time to precancer outcome using shared random effects. The model uses a discretization of the time scale to allow for closed-form likelihood expressions, thereby avoiding high-dimensional integration of the random effects. The method handles an interval-censored time-to-event outcome due to intermittent clinical visits, incorporates sampling weights to deal with stratified sampling data, and can provide immediate and 5-year risk estimates that may inform clinical decision-making.
                </td>
            </tr>
            
        </table>
    </div>

    <button type="button" class="collapsible">Tentative: Statistical and machine learning methods for data integration in biomedical research</button>
    <div class="content">
        <table id="PUTSPEAKERNAMEHERE">
            <tr>
                <td class="organizer">
                    Qi Long (Organizer)
                </td>
            </tr>
            <tr>
                <td class="speaker">
                    Ying Guo
                </td>
            </tr>
            <tr>
                <td class="speaker">
                    Suprateek Kundu
                </td>
            </tr>
            <tr>
                <td class="speaker">
                    Ming Wang
                </td>
            </tr>
            <tr>
                <td class="speaker">
                    Ziyi Li
                </td>
            </tr>

            <tr>
                <td class="title">
                    A Regularized Blind Source Separation Framework for Unveiling Hidden Sources of Brain Functional Connectome  
                </td>
            </tr>
            <tr>
                <td class="abstract">
                    Ying Guo<br>
                    Emory University<br>
                    yguo2@emory.edu 
                </td>
            </tr>
            <tr>
                <td class="abstract">
                    Brain connectomics has become increasingly important in neuroimaging studies to advance understanding of neural circuits and their association with neurodevelopment, mental illnesses, and aging. These analyses often face major challenges, including the high dimensionality of brain networks, unknown latent sources underlying the observed connectivity, and the large number of brain connections leading to spurious findings. In this talk, we will introduce a novel regularized blind source separation (BSS) framework for reliable mapping of neural circuits underlying static and dynamic brain functional connectome. The proposed LOCUS methods achieve more efficient and reliable source separation for connectivity matrices using low-rank factorization, a novel angle-based sparsity regularization, and a temporal smoothness regularization. We develop a highly efficient iterative Node-Rotation algorithm that solves the non-convex optimization problem for learning LOCUS models. Simulation studies demonstrate that the proposed methods have consistently improved accuracy in retrieving latent connectivity traits. Application of LOCUS methods to the Philadelphia Neurodevelopmental Cohort (PNC) neuroimaging study generates considerably more reproducible findings in revealing underlying neural circuits and their association with demographic and clinical phenotypes, uncovers dynamic expression profiles of the circuits and the synchronization between them, and generates insights on gender differences in the neurodevelopment of brain circuits. 
                </td>
            </tr>

            <tr>
                <td class="title">
                    Flexible Bayesian Product Mixture Models for Vector Autoregressions
                </td>
            </tr>
            <tr>
                <td class="abstract">
                    Suprateek Kundu, PhD<br>
                    Associate Professor, Department of Biostatistics, The University of Texas at MD Anderson Cancer Center<br>
                    SKundu2@mdanderson.org
                </td>
            </tr>
            <tr>
                <td class="abstract">
                    Bayesian non-parametric methods based on Dirichlet process mixtures have seen tremendous success in various domains and are appealing in being able to borrow information by clustering samples that share identical parameters. However, such methods can face hurdles in heterogeneous settings where objects are expected to cluster only along a subset of axes or where clusters of samples share only a subset of identical parameters. We overcome such limitations by developing a novel class of product of Dirichlet process location-scale mixtures that enable independent clustering at multiple scales, which result in varying levels of information sharing across samples. First, we develop the approach for independent multivariate data. Subsequently we generalize it to multivariate time-series data under the framework of multi-subject Vector Autoregressive (VAR) models that is our primary focus, which go beyond parametric single-subject VAR models. We establish posterior consistency and develop efficient posterior computation for implementation. Extensive numerical studies involving VAR models show distinct advantages over competing methods, in terms of estimation, clustering, and feature selection accuracy. Our resting state fMRI analysis from the Human Connectome Project reveals biologically interpretable connectivity differences between distinct intelligence groups, while another air pollution application illustrates the superior forecasting accuracy compared to alternate methods.
                </td>
            </tr>

            <tr>
                <td class="title">
                    Enhancing Primary Outcome Analysis by Leveraging Information from Secondary Outcomes
                </td>
            </tr>
            <tr>
                <td class="abstract">
                    Ming Wang, PhD<br>
                    Associate Professor, Director of the MS program in Biostatistics, Department of Population and Quantitative Health Sciences, Case Western Reserve University School of Medicine<br>
                    mxw827@case.edu
                </td>
            </tr>
            <tr>
                <td class="abstract">
                    Many observational studies and clinical trials collect various secondary outcomes that may be highly correlated with the primary endpoint. Typically, these secondary outcomes are analyzed separately from the primary analysis. However, leveraging secondary outcome data can significantly enhance the precision of primary outcome estimates. In this work, we will introduce recently developed methods that demonstrate how primary outcome estimation efficiency can be improved by incorporating information from secondary outcomes. We will explore scenarios involving single and multiple secondary outcomes, motivated from real-world clinical applications. The proposed methods will employ empirical likelihood-based weighting adaptive to different types of secondary outcomes. This innovative framework remains robust against model misspecifications in secondary data and can be flexibly extended to address various complex secondary outcomes. Both theoretical and simulation studies showcase efficiency gain. Finally, we will apply these methods to assess risk factors for cardiovascular diseases in the Atherosclerosis Risk in Communities (ARIC) study.
                </td>
            </tr>

            <tr>
                <td class="title">
                    Accommodating time-varying heterogeneity in risk estimation under the Cox model: a transfer learning approach
                </td>
            </tr>
            <tr>
                <td class="abstract">
                    Ziyi Li (presenter), Yu Shen, Jing Ning<br>
                    MD Anderson Cancer Center<br>
                    ZLi16@mdanderson.org
                </td>
            </tr>
            <tr>
                <td class="abstract">
                    Transfer learning has attracted increasing attention in recent years for adaptively borrowing information across different data cohorts in various settings. Cancer registries have been widely used in clinical research because of their easy accessibility and large sample size. Our method is motivated by the question of how to utilize cancer registry data as a complement to improve the estimation precision of individual risks of death for inflammatory breast cancer (IBC) patients at The University of Texas MD Anderson Cancer Center. When transferring information for risk estimation based on the cancer registries (i.e., source cohort) to a single cancer center (i.e., target cohort), time-varying population heterogeneity needs to be appropriately acknowledged. However, there is no literature on how to adaptively transfer knowledge on risk estimation with time-to-event data from the source cohort to the target cohort while adjusting for time-varying differences in event risks between the two sources. Our goal is to address this statistical challenge by developing a transfer learning approach under the Cox proportional hazards model. To allow data-adaptive levels of information borrowing, we impose Lasso penalties on the discrepancies in regression coefficients and baseline hazard functions between the two cohorts, which are jointly solved in the proposed transfer learning algorithm. As shown in the extensive simulation studies, the proposed method yields more precise individualized risk estimation than using the target cohort alone. Meanwhile, our method demonstrates satisfactory robustness against cohort differences compared with the method that directly combines the target and source data in the Cox model. We develop a more accurate risk estimation model for the MD Anderson IBC cohort given various treatment and baseline covariates, while adaptively borrowing information from the National Cancer Database to improve risk assessment.
                </td>
            </tr>

        </table>
    </div>

    <button type="button" class="collapsible">Tentative: Generalizability consideration in heterogeneous data</button>
    <div class="content">
        <table id="PUTSPEAKERNAMEHERE">
            <tr>
                <td class="organizer">
                    Menggang Yu (Organizer)
                </td>
            </tr>
            <tr>
                <td class="speaker">
                    Jeremy Taylor
                </td>
            </tr>
            <tr>
                <td class="speaker">
                    Lu Tian
                </td>
            </tr>
            <tr>
                <td class="speaker">
                    Menggang Yu
                </td>
            </tr>
            <tr>
                <td class="speaker">
                    Ruth Pfeiffer
                </td>
            </tr>

            <tr>
                <td class="title">
                    James-Stein approach for improving prediction of linear regression models by integrating external information from heterogeneous populations
                </td>
            </tr>
            <tr>
                <td class="abstract">
                    Jeremy M G Taylor, Peisong Han, Haoyue Li<br>
                    University of Michigan<br>
                    jmgt@umich.edu
                </td>
            </tr>
            <tr>
                <td class="abstract">
                    We consider the setting where (i) an internal study builds a linear regression model for prediction based on individual-level data, (ii) some external studies have fitted similar linear regression models that use only subsets of the covariates and provide coefficient estimates for the reduced models without individual-level data, and (iii) there is heterogeneity across these study populations. The goal is to integrate the external model summary information into fitting the internal model to improve prediction accuracy. We adapt the James-Stein shrinkage method to propose estimators that have guaranteed improvement in the prediction mean squared error after information integration, regardless of the degree of study population heterogeneity. We conduct comprehensive simulation studies to investigate the numerical performance of the proposed estimators. We also apply the method to enhance a prediction model for patella bone lead level in terms of blood lead level and other covariates by integrating summary information from published literature.
                </td>
            </tr>

            <tr>
                <td class="title">
                    Adaptive Prediction Strategy with Individualized Variable Selection 
                </td>
            </tr>
            <tr>
                <td class="abstract">
                    Lu Tian<br>
                    Stanford University<br>
                    lutian@stanford.edu
                </td>
            </tr>
            <tr>
                <td class="abstract">
                    Today, physicians have access to a wide array of tests for diagnosing and prognosticating medical conditions. Ideally, they would apply a high-quality prediction model, utilizing all relevant features as input, to facilitate appropriate decision-making regarding treatment selection or risk assessment. However, not all features used in these prediction models are readily available to patients and physicians without incurring some costs. In practice, predictors are typically gathered as needed in a sequential manner, while the physician continually evaluates information dynamically. This process continues until sufficient information is acquired, and the physician gains reasonable confidence in making a decision. Importantly, the prospective information to collect may differ for each patient and depend on the predictor values already known. In this paper, we present a novel dynamic prediction rule designed to determine the optimal order of acquiring prediction features in predicting a clinical outcome of interest. The objective is to maximize prediction accuracy while minimizing the cost associated with measuring prediction features for individual subjects. To achieve this, we employ reinforcement learning, where the agent must decide on the best action at each step: either making a clinical decision with available information or continuing to collect new predictors based on the current state of knowledge. To evaluate the efficacy of the proposed dynamic prediction strategy, extensive simulation studies have been conducted. Additionally, we provide two real data examples to illustrate the practical application of our method. 
                </td>
            </tr>

            <tr>
                <td class="title">
                    Entropy Balancing for Causal Generalization with Target Sample Summary Information
                </td>
            </tr>
            <tr>
                <td class="abstract">
                    Menggang Yu, PhD<br>
                    Department of Biostatistics, University of Michigan<br>
                    meyu@biostat.wisc.edu
                </td>
            </tr>
            <tr>
                <td class="abstract">
                    In this talk, we focus on estimating the average treatment effect (ATE) of a target population when individual-level data from a source population and summary-level data (e.g., first or second moments of certain covariates) from the target population are available. In the presence of heterogeneous treatment effect, the ATE of the target population can be different from that of the source population when distributions of treatment effect modifiers are dissimilar in these two populations, a phenomenon also known as covariate shift. Many methods have been developed to adjust for covariate shift, but most require individual covariates from a representative target sample. We develop a weighting approach based on summary-level information from the target sample to adjust for possible covariate shift in effect modifiers. In particular, weights of the treated and control groups within a source sample are calibrated by the summary-level information of the target sample. Our approach also seeks additional covariate balance between the treated and control groups in the source sample.
                </td>
            </tr>

            <tr>
                <td class="title">
                    Accommodating population differences in model validation
                </td>
            </tr>
            <tr>
                <td class="abstract">
                    Ruth Pfeiffer, Ph.D.<br>
                    Biostatistics Branch, National Cancer Institute, NIH, HHS, Bethesda, MD 20892-7244<br>
                    pfeiffer@mail.nih.gov
                </td>
            </tr>
            <tr>
                <td class="abstract">
                    Validation of risk prediction models in independent data provides a rigorous assessment of model performance. However, several differences between the populations that gave rise to the training and the validation data can lead to seemingly poor performance of a risk model. We formalize the notions of “similarity” of the training and validation data and define reproducibility and transportability. We address the impact of different predictor distributions and differences in verifying the outcome on model calibration, accuracy and discrimination. When individual level data from both the training and validation data sets are available, we propose and study weighted versions of the validation metrics that adjust for differences in the predictor distributions and in outcome verification to provide a more comprehensive assessment of model performance. We give conditions on the model and the training and validation populations that ensure a model’s reproducibility or transportability and show how to check them. We discuss approaches to recalibrate a model. As an illustration we develop and validate a prostate cancer risk model using data from two large North American prostate cancer prevention trials, the SELECT and PLCO trials. Joint work with Yiyao Chen, Mitchell H. Gail, Donna P. Ankerst
                </td>
            </tr>

        </table>
    </div>

    <button type="button" class="collapsible">Tentative: Survival analysis and its applications</button>
    <div class="content">
        <table id="PUTSPEAKERNAMEHERE">
            <tr>
                <td class="organizer">
                    Yichuan Zhao (Organizer)
                </td>
            </tr>
            <tr>
                <td class="speaker">
                    Gang Li
                </td>
            </tr>
            <tr>
                <td class="speaker">
                    Catherine Liu
                </td>
            </tr>
            <tr>
                <td class="speaker">
                    Yi Li
                </td>
            </tr>
            <tr>
                <td class="speaker">
                    Yichuan Zhao
                </td>
            </tr>

            <tr>
                <td class="title">
                    A Semiparametric Bayesian Instrumental Variable Analysis Method for Partly Interval-Censored Time-to-Event Outcome
                </td>
            </tr>
            <tr>
                <td class="abstract">
                    Gang Li<br>
                    UCLA        
                </td>
            </tr>
            <tr>
                <td class="abstract">
                    This paper develops a semiparametric Bayesian instrumental variable (IV) analysis method for estimating the causal effect of an endogenous variable when dealing with unobserved confounders and measurement errors with partly interval-censored time-to-event data, where event times are observed exactly for some subjects but left-censored, right-censored, or interval-censored for others. Our method is based on a two-stage Dirichlet process mixture instrumental variable (DPMIV) model which simultaneously models the first-stage random error term for the exposure variable and the second-stage random error term for the time-to-event outcome using a Gaussian mixture of the Dirichlet process (DPM) model. The DPM model can be broadly understood as a mixture model with an unspecified number of Gaussian components, which relaxes the normal error assumptions and allows the number of mixture components to be determined by the data. We develop an MCMC algorithm for the DPMIV model tailored for partly interval-censored data and conduct extensive simulations to assess the performance of our DPMIV method in comparison with some existing methods. Our simulations revealed that our proposed method is robust under different error distributions and can have far superior performance over some competing methods under a variety of scenarios. We further demonstrate the effectiveness of our approach on the UK Biobank study to investigate the causal effect of systolic blood pressure (SBP) on time-to-development of cardiovascular disease (CVD) from the diagnosis of diabetes mellitus (DM).
                </td>
            </tr>

            <tr>
                <td class="title">
                    CeCNN: Copula-Enhanced Convolutional Neural Networks in Joint Prediction of Refraction Error and Axial Length Based on Ultrawide Field Fundus Images
                </td>
            </tr>
            <tr>
                <td class="abstract">
                    Catherine Chunling Liu<br>
                    Hong Kong Polytechnic University<br>
                    catherine.chunling.liu@polyu.edu.hk                     
                </td>
            </tr>
            <tr>
                <td class="abstract">
                    Ultra-widefield (UWF) fundus images are replacing traditional fundus images in screening, detection, prediction, and treatment of complications related to myopia because their much broader visual range is advantageous for highly myopic eyes. Spherical equivalent (SE) is extensively used as the main myopia outcome measure, and axial length (AL) has drawn increasing interest as an important ocular component for assessing myopia. Cutting-edge studies show that SE and AL are strongly correlated. Using the joint information from SE and AL is potentially better than using either separately. In the deep learning community, though there is research on multiple-response tasks with a 3D image biomarker, dependence among responses is only sporadically taken into consideration. Inspired by the spirit that information extracted from the data by statistical methods can improve the prediction accuracy of deep learning models, we formulate a class of bivariate response regression models with a higher-order tensor biomarker, for the bivariate tasks of regression-classification and regression-regression. Specifically, we propose a copula-enhanced convolutional neural network (CeCNN) architecture that incorporates the dependence between responses through a Gaussian copula (with parameters estimated from a warm-up CNN) and uses the induced copula-likelihood loss with the backbone CNNs. We establish the statistical framework and algorithms for the aforementioned two bivariate tasks. We show that the CeCNN has better prediction accuracy after adding the dependency information to the backbone models. The modeling and the proposed CeCNN algorithm are applicable beyond the UWF scenario and can be effective with other backbones beyond ResNet and LeNet.
                </td>
            </tr>

            <tr>
                <td class="title">
                    Multi-task Learning for Gaussian Graphical Regressions with High Dimensional Covariates
                </td>
            </tr>
            <tr>
                <td class="abstract">
                    Yi Li, PhD <br>
                    M. Anthony Schork Collegiate Professor, Professor of Biostatistics, Professor of Global Public Health, School of Public Health, University of Michigan, Ann Arbor<br>
                    yili@umich.edu
                </td>
            </tr>
            <tr>
                <td class="abstract">
                    Gaussian graphical regression is a powerful approach for regressing the precision matrix of a Gaussian graphical model on covariates, which permits the response variables and covariates to outnumber the sample size. However, traditional approaches of fitting the model via separate node-wise lasso regressions overlook the network-induced structure among these regressions, leading to high error rates, particularly when the number of nodes is large. To address this issue, we propose a multi-task learning estimator for fitting Gaussian graphical regression models, which incorporates a cross-task group sparsity penalty and a within-task element-wise sparsity penalty to govern the sparsity of active covariates and their effects on the graph, respectively. We also develop an efficient augmented Lagrangian algorithm for computation, which solves subproblems with a semi-smooth Newton method. We further prove that our multi-task learning estimator has considerably lower error rates than the separate node-wise regression estimates, as the cross-task penalty enables borrowing information across tasks. To address the main challenge of entangled tasks in a complicated correlation structure, we establish a new tail probability bound for dependent heavy-tailed, for example, sub-exponential, variables with an arbitrary dependence structure, which is a useful theoretical result in its own right.  We examine the utility of our method through simulations and an application to a gene co-expression network study with brain cancer patients.
                </td>
            </tr>

            <tr>
                <td class="title">
                    Weighted empirical likelihood inference for the difference between the areas under two correlated ROC curves with right-censored data
                </td>
            </tr>
            <tr>
                <td class="abstract">
                    Yichuan Zhao <br>
                    Department of Mathematics and Statistics, Georgia State University<br>
                    yichuan@gsu.edu
                </td>
            </tr>
            <tr>
                <td class="abstract">
                    In this article, we propose the two-sample weighted empirical likelihood, building upon Chrzanowski’s (2014) method, to compare the area under the ROC curve of two correlated ROC curves. A normal approximation method is derived. We define a weighted empirical likelihood ratio and demonstrate that the resulting statistic follows a scaled chi-square distribution. Additionally, to improve the accuracy of confidence intervals for small sample sizes, we employ a calibration method known as the adjusted empirical likelihood. Extensive simulations are conducted to assess the excellent finite-sample performance of our proposed weighted empirical likelihood method. To further illustrate the practical applicability of our methodology, we provide a real-world example showcasing its effectiveness.
                </td>
            </tr>

        </table>
    </div>

    <table id="PUTSPEAKERNAMEHERE">
        <tr>
            <td class="title">
                Analysis of multi-outcomes and multi-source data
            </td>
        </tr>
        <tr>
            <td class="organizer">
                Zhezhen Jin (Organizer)
            </td>
        </tr>
        <tr>
            <td class="speaker">
                Xiaonan Xue
            </td>
        </tr>
        <tr>
            <td class="speaker">
                Yongzhao Shao
            </td>
        </tr>
        <tr>
            <td class="speaker">
                Shanshan Ding
            </td>
        </tr>
        <tr>
            <td class="speaker">
                Lihui Zhao
            </td>
        </tr>
    </table>

    <table id="PUTSPEAKERNAMEHERE">
        <tr>
            <td class="title">
                Recent Development of Statistical Methods for Complex Survival Data in Medical Studies
            </td>
        </tr>
        <tr>
            <td class="organizer">
                Yanqing Sun (Organizer)
            </td>
        </tr>
        <tr>
            <td class="speaker">
                Wenqing He
            </td>
        </tr>
        <tr>
            <td class="speaker">
                Yanqing Sun
            </td>
        </tr>
        <tr>
            <td class="speaker">
                Chiung-Yu Huang
            </td>
        </tr>
        <tr>
            <td class="speaker">
                Grace Yi
            </td>
        </tr>
    </table>

    <table id="PUTSPEAKERNAMEHERE">
        <tr>
            <td class="title">
                Recent developments in Survival Analysis and Statistical Machine Learning
            </td>
        </tr>
        <tr>
            <td class="organizer">
                Tony Sun (Organizer)
            </td>
        </tr>
        <tr>
            <td class="speaker">
                Jian Huang
            </td>
        </tr>
        <tr>
            <td class="speaker">
                Chengchun Shi
            </td>
        </tr>
        <tr>
            <td class="speaker">
                Yifan Cui
            </td>
        </tr>
        <tr>
            <td class="speaker">
                Qixian Zhong
            </td>
        </tr>
    </table>

    <table id="PUTSPEAKERNAMEHERE">
        <tr>
            <td class="title">
                Flexible statistical learning for complex data
            </td>
        </tr>
        <tr>
            <td class="organizer">
                Yufeng Liu (Organizer)
            </td>
        </tr>
        <tr>
            <td class="speaker">
                Eric Chi
            </td>
        </tr>
        <tr>
            <td class="speaker">
                Ali Shojaie
            </td>
        </tr>
        <tr>
            <td class="speaker">
                Zhengyuan Zhu
            </td>
        </tr>
        <tr>
            <td class="speaker">
                Yufeng Liu
            </td>
        </tr>
    </table>

    <table id="PUTSPEAKERNAMEHERE">
        <tr>
            <td class="title">
                The integration of high dimensional data in JOiNT MODELS
            </td>
        </tr>
        <tr>
            <td class="organizer">
                Virginie Rondeau (Organizer)
            </td>
        </tr>
        <tr>
            <td class="speaker">
                Pedro Miranda AFONSO
            </td>
        </tr>
        <tr>
            <td class="speaker">
                Cecile Proust Lima
            </td>
        </tr>
        <tr>
            <td class="speaker">
                Denis Rustand
            </td>
        </tr>
        <tr>
            <td class="speaker">
                Manel Rakez
            </td>
        </tr>
    </table>

    <table id="PUTSPEAKERNAMEHERE">
        <tr>
            <td class="title">
                Dynamic prediction
            </td>
        </tr>
        <tr>
            <td class="organizer">
                Jessica Barrett (Organizer)
            </td>
        </tr>
        <tr>
            <td class="speaker">
                Hein Putter
            </td>
        </tr>
        <tr>
            <td class="speaker">
                Dimitris Rizopoulos
            </td>
        </tr>
        <tr>
            <td class="speaker">
                Danilo Alvares
            </td>
        </tr>
        <tr>
            <td class="speaker">
                Liang Li
            </td>
        </tr>
    </table>

    <table id="PUTSPEAKERNAMEHERE">
        <tr>
            <td class="title">
                Dependence Modeling
            </td>
        </tr>
        <tr>
            <td class="organizer">
                Wolfgang Trutschnig & Sebastian Fuchs (Organizer)
            </td>
        </tr>
        <tr>
            <td class="speaker">
                Damjana Kokol Bukovsek
            </td>
        </tr>
        <tr>
            <td class="speaker">
                Nik Stopar
            </td>
        </tr>
        <tr>
            <td class="speaker">
                Jonathan Ansari
            </td>
        </tr>
        <tr>
            <td class="speaker">
                Patrick Langthaler
            </td>
        </tr>
    </table>

    <table id="PUTSPEAKERNAMEHERE">
        <tr>
            <td class="title">
                Multivariate and Complex Longitudinal Data
            </td>
        </tr>
        <tr>
            <td class="organizer">
                Georg Zimmermann (Organizer)
            </td>
        </tr>
        <tr>
            <td class="speaker">
                Geert Molenberghs
            </td>
        </tr>
        <tr>
            <td class="speaker">
                Frank Konietschke
            </td>
        </tr>
        <tr>
            <td class="speaker">
                Somnath Datta
            </td>
        </tr>
        <tr>
            <td class="speaker">
                Kelly van Lancker
            </td>
        </tr>
    </table>

    <table id="PUTSPEAKERNAMEHERE">
        <tr>
            <td class="title">
                Precision Medicine and Reinforcement Learning
            </td>
        </tr>
        <tr>
            <td class="organizer">
                Simon Hirländer (Organizer)
            </td>
        </tr>
        <tr>
            <td class="speaker">
                Danyu Lin
            </td>
        </tr>
        <tr>
            <td class="speaker">
                Richard Cook
            </td>
        </tr>
        <tr>
            <td class="speaker">
                Limin Peng
            </td>
        </tr>
        <tr>
            <td class="speaker">
                Lei Liu
            </td>
        </tr>
    </table>

    <table id="PUTSPEAKERNAMEHERE">
        <tr>
            <td class="title">
                General topics in multi-outcome data
            </td>
        </tr>
        <tr>
            <td class="organizer">
                Zhezhen Jin (Organizer)
            </td>
        </tr>
        <tr>
            <td class="speaker">
                Xuewen Lu
            </td>
        </tr>
        <tr>
            <td class="speaker">
                Yingwei Paul Peng
            </td>
        </tr>
        <tr>
            <td class="speaker">
                Yuping Wang
            </td>
        </tr>
        <tr>
            <td class="speaker">
                Nicolas Dietrich
            </td>
        </tr>
    </table>

    <table id="PUTSPEAKERNAMEHERE">
        <tr>
            <td class="title">
                TBD
            </td>
        </tr>
        <tr>
            <td class="organizer">
                Gang Li (Organizer)
            </td>
        </tr>
        <tr>
            <td class="speaker">
                Hua Zhou
            </td>
        </tr>
        <tr>
            <td class="speaker">
                Lang Wu
            </td>
        </tr>
        <tr>
            <td class="speaker">
                Ying Lu
            </td>
        </tr>
        <tr>
            <td class="speaker">
                Jin Zhou
            </td>
        </tr>
    </table>

    <table id="PUTSPEAKERNAMEHERE">
        <tr>
            <td class="title">
                Topics in Advanced Multi-outcome Data Analysis
            </td>
        </tr>
        <tr>
            <td class="organizer">
                Lei Liu (Organizer)
            </td>
        </tr>
        <tr>
            <td class="speaker">
                Jianwen Cai
            </td>
        </tr>
        <tr>
            <td class="speaker">
                Donglin Zeng
            </td>
        </tr>
        <tr>
            <td class="speaker">
                Yuanjia Wang
            </td>
        </tr>
        <tr>
            <td class="speaker">
                Haibo Zhou
            </td>
        </tr>
    </table>

    <script>
        var coll = document.getElementsByClassName("collapsible");
        var i;
        
        for (i = 0; i < coll.length; i++) {
          coll[i].addEventListener("click", function() {
            this.classList.toggle("active");
            var content = this.nextElementSibling;
            if (content.style.display === "block") {
              content.style.display = "none";
            } else {
              content.style.display = "block";
            }
          });
        }
    </script>
<!--
    <table>
        <tr>
            <td class="date" rowspan="2">
                8:30am
            </td>
            <td class="title-special">
                Registration and Coffee &amp; Tea!
            </td>
        </tr>
        <tr>
            <td class="abstract">
                Here&rsquo;s a section in the program that isn&rsquo;t a talk. 
                Notice that the title is styled differently than the ones for talks.
            </td>
        </tr>
    </table>

    <table id="PUTSPEAKERNAMEHERE">
        <tr>
            <td class="date" rowspan="3">
                9:00am
            </td>
            <td class="title">
                Interesting Title of a Talk 
            </td>
        </tr>
        <tr>
            <td class="speaker">
                Speaker Name (University)
            </td>
        </tr>
        <tr>
            <td class="abstract">
                Here&rsquo;s where you put the abstract of the talk. Notice that with MathJax you can include mathematical notation in the abstract like \(f(x)=3x-7\) or like \(h^0(X_t,\omega_{X_t}^{\otimes m})\) or whatever you want. Just notice the MathJax line in the head of this HTML document that allows this. I&rsquo;m going to blab just a tiny bit more in this abstract, but all the other abstracts below, except the ones for the plenary talks, will be just <i>Lorem Ipsum</i> text that needs to be replaced by real abstracts.
            </td>
        </tr>
    </table>

    <table id="PUTSPEAKERNAMEHERE">
        <tr>
            <td class="date" rowspan="3">
                9:25am
            </td>
            <td class="title">
                Interesting Title of a Talk 
            </td>
        </tr>
        <tr>
            <td class="speaker">
                Speaker Name (University)
            </td>
        </tr>
        <tr>
            <td class="abstract">
                Filler text: Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vestibulum dignissim et est et euismod. Fusce et metus tempus, pellentesque ex at, convallis nulla. Ut fringilla commodo tincidunt. Fusce sed est eu massa placerat iaculis eu at mauris. Nullam ut mollis nisi, quis malesuada risus. Interdum et malesuada fames ac ante ipsum primis in faucibus. Nam ipsum tortor, suscipit non tincidunt vel, bibendum in libero. Nulla facilisi. Pellentesque vitae neque metus. Cras quis est pharetra, vestibulum nisl et, viverra ipsum. Etiam porta dignissim purus, quis tempor metus volutpat eu. Praesent pulvinar libero eget purus tincidunt finibus.
            </td>
        </tr>
    </table>

    <table id="PUTSPEAKERNAMEHERE">
        <tr>
            <td class="date" rowspan="3">
                9:50am
            </td>
            <td class="title">
                Interesting Title of a Talk 
            </td>
        </tr>
        <tr>
            <td class="speaker">
                Speaker Name (University)
            </td>
        </tr>
        <tr>
            <td class="abstract">
                Filler text: Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vestibulum dignissim et est et euismod. Fusce et metus tempus, pellentesque ex at, convallis nulla. Ut fringilla commodo tincidunt. Fusce sed est eu massa placerat iaculis eu at mauris. Nullam ut mollis nisi, quis malesuada risus. Interdum et malesuada fames ac ante ipsum primis in faucibus. Nam ipsum tortor, suscipit non tincidunt vel, bibendum in libero. Nulla facilisi. Pellentesque vitae neque metus. Cras quis est pharetra, vestibulum nisl et, viverra ipsum. Etiam porta dignissim purus, quis tempor metus volutpat eu. Praesent pulvinar libero eget purus tincidunt finibus.
            </td>
        </tr>
    </table>

    <table id="PUTSPEAKERNAMEHERE">
        <tr>
            <td class="date" rowspan="3">
                10:15am
            </td>
            <td class="title">
                Interesting Title of a Talk 
            </td>
        </tr>
        <tr>
            <td class="speaker">
                Speaker Name (University)
            </td>
        </tr>
        <tr>
            <td class="abstract">
                Filler text: Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vestibulum dignissim et est et euismod. Fusce et metus tempus, pellentesque ex at, convallis nulla. Ut fringilla commodo tincidunt. Fusce sed est eu massa placerat iaculis eu at mauris. Nullam ut mollis nisi, quis malesuada risus. Interdum et malesuada fames ac ante ipsum primis in faucibus. Nam ipsum tortor, suscipit non tincidunt vel, bibendum in libero. Nulla facilisi. Pellentesque vitae neque metus. Cras quis est pharetra, vestibulum nisl et, viverra ipsum. Etiam porta dignissim purus, quis tempor metus volutpat eu. Praesent pulvinar libero eget purus tincidunt finibus.
            </td>
        </tr>
    </table>

    <table>
        <tr>
            <td class="date" rowspan="2">
                10:40am
            </td>
            <td class="title-special">
                Coffee &amp; Tea Break
            </td>
        </tr>
        <tr>
            <td class="abstract">
                
            </td>
        </tr>
    </table>

    <table class="plenary">
        <tr>
            <td class="date" rowspan="3">
                11:00am
            </td>
            <td class="title">
                This is a Plenary Talk!
            </td>
        </tr>
        <tr>
            <td class="speaker">
                Plenary Speaker
            </td>
        </tr>
        <tr>
            <td class="abstract">
                Here&rsquo;s the abstract for the plenary talk! Notice again that the formatting of this time-block is a bit different that the rest of of the talks.
                Filler text: Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vestibulum dignissim et est et euismod. Fusce et metus tempus, pellentesque ex at, convallis nulla. Ut fringilla commodo tincidunt. Fusce sed est eu massa placerat iaculis eu at mauris. Nullam ut mollis nisi, quis malesuada risus. Interdum et malesuada fames ac ante ipsum primis in faucibus. Nam ipsum tortor, suscipit non tincidunt vel, bibendum in libero. Nulla facilisi. Pellentesque vitae neque metus. Cras quis est pharetra, vestibulum nisl et, viverra ipsum. Etiam porta dignissim purus, quis tempor metus volutpat eu. Praesent pulvinar libero eget purus tincidunt finibus.
            </td>
        </tr>
    </table>

    <table>
        <tr>
            <td class="date" rowspan="2">
                Noon
            </td>
            <td class="title-special">
                Lunch
            </td>
        </tr>
        <tr>
            <td class="abstract">
                
            </td>
        </tr>
    </table>

    <table id="PUTSPEAKERNAMEHERE">
        <tr>
            <td class="date" rowspan="3">
                1:30pm
            </td>
            <td class="title">
                Interesting Title of a Talk 
            </td>
        </tr>
        <tr>
            <td class="speaker">
                Speaker Name (University)
            </td>
        </tr>
        <tr>
            <td class="abstract">
                Filler text: Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vestibulum dignissim et est et euismod. Fusce et metus tempus, pellentesque ex at, convallis nulla. Ut fringilla commodo tincidunt. Fusce sed est eu massa placerat iaculis eu at mauris. Nullam ut mollis nisi, quis malesuada risus. Interdum et malesuada fames ac ante ipsum primis in faucibus. Nam ipsum tortor, suscipit non tincidunt vel, bibendum in libero. Nulla facilisi. Pellentesque vitae neque metus. Cras quis est pharetra, vestibulum nisl et, viverra ipsum. Etiam porta dignissim purus, quis tempor metus volutpat eu. Praesent pulvinar libero eget purus tincidunt finibus.
            </td>
        </tr>
    </table>

    <table id="PUTSPEAKERNAMEHERE">
        <tr>
            <td class="date" rowspan="3">
                1:55pm
            </td>
            <td class="title">
                Interesting Title of a Talk 
            </td>
        </tr>
        <tr>
            <td class="speaker">
                Speaker Name (University)
            </td>
        </tr>
        <tr>
            <td class="abstract">
                Filler text: Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vestibulum dignissim et est et euismod. Fusce et metus tempus, pellentesque ex at, convallis nulla. Ut fringilla commodo tincidunt. Fusce sed est eu massa placerat iaculis eu at mauris. Nullam ut mollis nisi, quis malesuada risus. Interdum et malesuada fames ac ante ipsum primis in faucibus. Nam ipsum tortor, suscipit non tincidunt vel, bibendum in libero. Nulla facilisi. Pellentesque vitae neque metus. Cras quis est pharetra, vestibulum nisl et, viverra ipsum. Etiam porta dignissim purus, quis tempor metus volutpat eu. Praesent pulvinar libero eget purus tincidunt finibus.
            </td>
        </tr>
    </table>

    <table>
        <tr>
            <td class="date" rowspan="2">
                2:50pm
            </td>
            <td class="title-special">
                Coffee &amp; Tea Break
            </td>
        </tr>
        <tr>
            <td class="abstract">
                 
            </td>
        </tr>
    </table>

    <table id="PUTSPEAKERNAMEHERE">
        <tr>
            <td class="date" rowspan="3">
                3:10pm
            </td>
            <td class="title">
                Interesting Title of a Talk 
            </td>
        </tr>
        <tr>
            <td class="speaker">
                Speaker Name (University)
            </td>
        </tr>
        <tr>
            <td class="abstract">
                Filler text: Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vestibulum dignissim et est et euismod. Fusce et metus tempus, pellentesque ex at, convallis nulla. Ut fringilla commodo tincidunt. Fusce sed est eu massa placerat iaculis eu at mauris. Nullam ut mollis nisi, quis malesuada risus. Interdum et malesuada fames ac ante ipsum primis in faucibus. Nam ipsum tortor, suscipit non tincidunt vel, bibendum in libero. Nulla facilisi. Pellentesque vitae neque metus. Cras quis est pharetra, vestibulum nisl et, viverra ipsum. Etiam porta dignissim purus, quis tempor metus volutpat eu. Praesent pulvinar libero eget purus tincidunt finibus.
            </td>
        </tr>
    </table>

    <table id="PUTSPEAKERNAMEHERE">
        <tr>
            <td class="date" rowspan="3">
                3:35pm
            </td>
            <td class="title">
                Interesting Title of a Talk 
            </td>
        </tr>
        <tr>
            <td class="speaker">
                Speaker Name (University)
            </td>
        </tr>
        <tr>
            <td class="abstract">
                Filler text: Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vestibulum dignissim et est et euismod. Fusce et metus tempus, pellentesque ex at, convallis nulla. Ut fringilla commodo tincidunt. Fusce sed est eu massa placerat iaculis eu at mauris. Nullam ut mollis nisi, quis malesuada risus. Interdum et malesuada fames ac ante ipsum primis in faucibus. Nam ipsum tortor, suscipit non tincidunt vel, bibendum in libero. Nulla facilisi. Pellentesque vitae neque metus. Cras quis est pharetra, vestibulum nisl et, viverra ipsum. Etiam porta dignissim purus, quis tempor metus volutpat eu. Praesent pulvinar libero eget purus tincidunt finibus.
            </td>
        </tr>
    </table>

    <table class="plenary">
        <tr>
            <td class="date" rowspan="3">
                4:00pm
            </td>
            <td class="title">
                This is Another Plenary Talk!
            </td>
        </tr>
        <tr>
            <td class="speaker">
                Plenary Speaker
            </td>
        </tr>
        <tr>
            <td class="abstract">
                Filler text: Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vestibulum dignissim et est et euismod. Fusce et metus tempus, pellentesque ex at, convallis nulla. Ut fringilla commodo tincidunt. Fusce sed est eu massa placerat iaculis eu at mauris. Nullam ut mollis nisi, quis malesuada risus. Interdum et malesuada fames ac ante ipsum primis in faucibus. Nam ipsum tortor, suscipit non tincidunt vel, bibendum in libero. Nulla facilisi. Pellentesque vitae neque metus. Cras quis est pharetra, vestibulum nisl et, viverra ipsum. Etiam porta dignissim purus, quis tempor metus volutpat eu. Praesent pulvinar libero eget purus tincidunt finibus.
            </td>
        </tr>
    </table>
-->
    <!--<footer>
        &copy; Conference Organizers
        &nbsp;|&nbsp; <a href="https://profiles.wustl.edu/en/persons/lei-liu">Lei Liu</a>
    </footer>-->

</body>
</html>

